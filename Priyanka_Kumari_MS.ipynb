{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqe8dgarTHyWxcPu2exEJ6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priyanka4678/Assignment_on_python_for_DSA/blob/main/Priyanka_Kumari_MS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odxOkjaI7gHJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('/content/titanic_dataset (2).csv')"
      ],
      "metadata": {
        "id": "zcwT0kQ0g3jJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "mhY8VLoDg8o4",
        "outputId": "17a8be92-0fa9-4607-8741-18dee1f064a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "5            6         0       3   \n",
              "6            7         0       1   \n",
              "7            8         0       3   \n",
              "8            9         1       3   \n",
              "9           10         1       2   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                           Allen, Mr. William Henry    male  35.0      0   \n",
              "5                                   Moran, Mr. James    male   NaN      0   \n",
              "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
              "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
              "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
              "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3      0            113803  53.1000  C123        S  \n",
              "4      0            373450   8.0500   NaN        S  \n",
              "5      0            330877   8.4583   NaN        Q  \n",
              "6      0             17463  51.8625   E46        S  \n",
              "7      1            349909  21.0750   NaN        S  \n",
              "8      2            347742  11.1333   NaN        S  \n",
              "9      0            237736  30.0708   NaN        C  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d2f7420a-f985-4305-a8b4-21f2698195e7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Moran, Mr. James</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330877</td>\n",
              "      <td>8.4583</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>McCarthy, Mr. Timothy J</td>\n",
              "      <td>male</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17463</td>\n",
              "      <td>51.8625</td>\n",
              "      <td>E46</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Palsson, Master. Gosta Leonard</td>\n",
              "      <td>male</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>349909</td>\n",
              "      <td>21.0750</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
              "      <td>female</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>347742</td>\n",
              "      <td>11.1333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
              "      <td>female</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>237736</td>\n",
              "      <td>30.0708</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2f7420a-f985-4305-a8b4-21f2698195e7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d2f7420a-f985-4305-a8b4-21f2698195e7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d2f7420a-f985-4305-a8b4-21f2698195e7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q50NsYwag_p3",
        "outputId": "5bd2cc3c-eb04-4474-9410-3a39a63d2090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(891, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP6jWSvnhFhz",
        "outputId": "5d74d80c-52e4-4aa3-9508-985e37d4f58a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpep2G--hH_H",
        "outputId": "63f86f40-004a-459d-bf4c-93f56c2c33ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId      0\n",
              "Survived         0\n",
              "Pclass           0\n",
              "Name             0\n",
              "Sex              0\n",
              "Age            177\n",
              "SibSp            0\n",
              "Parch            0\n",
              "Ticket           0\n",
              "Fare             0\n",
              "Cabin          687\n",
              "Embarked         2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['PassengerId'].nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEHQ2NpRhMv_",
        "outputId": "79a4fe57-5bfc-4d03-a7d3-41eecfa296b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "891"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Of4nqR4jiQD2",
        "outputId": "50003e92-965e-4d9c-b971-dfef6aad34b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
              "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Age']=data['Age'].fillna(data['Age'].median())"
      ],
      "metadata": {
        "id": "Cx23XDAli_zW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tf2-Ut2lcQ5",
        "outputId": "5ff4f2c0-9656-4ce1-bdc7-5d02e0e98b64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId      0\n",
              "Survived         0\n",
              "Pclass           0\n",
              "Name             0\n",
              "Sex              0\n",
              "Age              0\n",
              "SibSp            0\n",
              "Parch            0\n",
              "Ticket           0\n",
              "Fare             0\n",
              "Cabin          687\n",
              "Embarked         2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Embarked']=data['Embarked'].fillna(data['Embarked'].mode())"
      ],
      "metadata": {
        "id": "j0oShWmZlgiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo54ShqNnucA",
        "outputId": "873a1537-1f9d-4c5c-d568-15958dfd646d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId      0\n",
              "Survived         0\n",
              "Pclass           0\n",
              "Name             0\n",
              "Sex              0\n",
              "Age              0\n",
              "SibSp            0\n",
              "Parch            0\n",
              "Ticket           0\n",
              "Fare             0\n",
              "Cabin          687\n",
              "Embarked         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data1=data.drop('Cabin',axis=1)"
      ],
      "metadata": {
        "id": "Xn9z3Al3l1xQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1=pd.get_dummies(data1)"
      ],
      "metadata": {
        "id": "fZX1lmvvmSla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "Y6OIRBFwo1Sw",
        "outputId": "6e0dcb98-4b74-4e42-8c2e-ebb86262f9ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare  \\\n",
              "0            1         0       3  22.0      1      0   7.2500   \n",
              "1            2         1       1  38.0      1      0  71.2833   \n",
              "2            3         1       3  26.0      0      0   7.9250   \n",
              "3            4         1       1  35.0      1      0  53.1000   \n",
              "4            5         0       3  35.0      0      0   8.0500   \n",
              "\n",
              "   Name_Abbing, Mr. Anthony  Name_Abbott, Mr. Rossmore Edward  \\\n",
              "0                         0                                 0   \n",
              "1                         0                                 0   \n",
              "2                         0                                 0   \n",
              "3                         0                                 0   \n",
              "4                         0                                 0   \n",
              "\n",
              "   Name_Abbott, Mrs. Stanton (Rosa Hunt)  ...  Ticket_W./C. 6607  \\\n",
              "0                                      0  ...                  0   \n",
              "1                                      0  ...                  0   \n",
              "2                                      0  ...                  0   \n",
              "3                                      0  ...                  0   \n",
              "4                                      0  ...                  0   \n",
              "\n",
              "   Ticket_W./C. 6608  Ticket_W./C. 6609  Ticket_W.E.P. 5734  Ticket_W/C 14208  \\\n",
              "0                  0                  0                   0                 0   \n",
              "1                  0                  0                   0                 0   \n",
              "2                  0                  0                   0                 0   \n",
              "3                  0                  0                   0                 0   \n",
              "4                  0                  0                   0                 0   \n",
              "\n",
              "   Ticket_WE/P 5735  Embarked_C  Embarked_Q  Embarked_S  Embarked_Unknown  \n",
              "0                 0           0           0           1                 0  \n",
              "1                 0           1           0           0                 0  \n",
              "2                 0           0           0           1                 0  \n",
              "3                 0           0           0           1                 0  \n",
              "4                 0           0           0           1                 0  \n",
              "\n",
              "[5 rows x 1585 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-767017b5-8b46-4b5c-acd2-a51ef2e487f0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Name_Abbing, Mr. Anthony</th>\n",
              "      <th>Name_Abbott, Mr. Rossmore Edward</th>\n",
              "      <th>Name_Abbott, Mrs. Stanton (Rosa Hunt)</th>\n",
              "      <th>...</th>\n",
              "      <th>Ticket_W./C. 6607</th>\n",
              "      <th>Ticket_W./C. 6608</th>\n",
              "      <th>Ticket_W./C. 6609</th>\n",
              "      <th>Ticket_W.E.P. 5734</th>\n",
              "      <th>Ticket_W/C 14208</th>\n",
              "      <th>Ticket_WE/P 5735</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "      <th>Embarked_Unknown</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1585 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-767017b5-8b46-4b5c-acd2-a51ef2e487f0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-767017b5-8b46-4b5c-acd2-a51ef2e487f0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-767017b5-8b46-4b5c-acd2-a51ef2e487f0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGdgzvgSo4XB",
        "outputId": "a4e71517-c1d0-4f24-fefa-62a2a00cf321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(891, 1585)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=data1.drop('Survived',axis=1)\n",
        "y=data1['Survived']"
      ],
      "metadata": {
        "id": "RMGPXJHlpAgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=42,test_size=0.2)"
      ],
      "metadata": {
        "id": "jwEY3xelqgC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **KNN Model**"
      ],
      "metadata": {
        "id": "-nrHHNMormU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "XViNomYepbga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score"
      ],
      "metadata": {
        "id": "TMOii27qqutN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric_k=[]\n",
        "neighbors=np.arange(3,15)"
      ],
      "metadata": {
        "id": "7YVzamXoqNRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in neighbors:\n",
        "  classifier=KNeighborsClassifier(n_neighbors=k,metric='euclidean')\n",
        "  classifier.fit(x_train,y_train)\n",
        "  y_prediction=classifier.predict(x_test)\n",
        "  acc=accuracy_score(y_test,y_prediction)\n",
        "  metric_k.append(acc)"
      ],
      "metadata": {
        "id": "vQTqK1xxqQsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric_k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GER3Nwc8qTlP",
        "outputId": "7b92f0f0-9b10-42fb-c20c-5fe64dc928f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5865921787709497,\n",
              " 0.6424581005586593,\n",
              " 0.659217877094972,\n",
              " 0.659217877094972,\n",
              " 0.659217877094972,\n",
              " 0.6480446927374302,\n",
              " 0.6536312849162011,\n",
              " 0.6424581005586593,\n",
              " 0.6368715083798883,\n",
              " 0.6368715083798883,\n",
              " 0.6480446927374302,\n",
              " 0.6480446927374302]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(neighbors,metric_k,'o-')\n",
        "plt.xlabel(\"K Value\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.grid()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "N13gO9Etq097",
        "outputId": "0bfc847a-1693-4027-cf93-fa5c16d68ff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier=KNeighborsClassifier(n_neighbors=5,metric='euclidean')\n",
        "classifier.fit(x_train,y_train)\n",
        "y_prediction=classifier.predict(x_test)"
      ],
      "metadata": {
        "id": "lnaECt4kq5Gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy is :',accuracy_score(y_test,y_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUys63m6q941",
        "outputId": "02609a55-a39c-4e92-86e7-67b3bf2dea4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is : 0.659217877094972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test,y_prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_Ul8J6xrDdf",
        "outputId": "33a0097b-0b00-4544-fc3b-1945493c31b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[88, 17],\n",
              "       [44, 30]])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **SVM Model**"
      ],
      "metadata": {
        "id": "1ikgz7mCrtBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "YuD5NlNxrGfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_cls=SVC(kernel='linear')\n",
        "svm_cls=svm_cls.fit(x_train,y_train)\n",
        "y_pred_svm=svm_cls.predict(x_test)"
      ],
      "metadata": {
        "id": "jLuBYdcysKv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score"
      ],
      "metadata": {
        "id": "zTeAnnVvrOB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test,y_pred_svm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bs0NvqmrRBf",
        "outputId": "15bbb59f-b801-4a7e-9253-9fd614dfb7b1"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[96,  9],\n",
              "       [19, 55]])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test,y_pred_svm)"
      ],
      "metadata": {
        "id": "JEjWoCg9rT_X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df61c0f7-9a93-4312-9381-7ce756a52a4a"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8435754189944135"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Hold Out Technique**"
      ],
      "metadata": {
        "id": "bWEuIeLJwu5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "LR_model=LogisticRegression()\n",
        "LR_model=LR_model.fit(x_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kVuHyKRv8qH",
        "outputId": "bcb10895-32c2-4d72-fe5a-24529ae08485"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score_LR=LR_model.score(x_test,y_test)\n",
        "score_LR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu6zNWDzwfD1",
        "outputId": "af357e6b-8f57-4c0e-d1fa-e377b168c4c9"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8100558659217877"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **K Fold Cross Validation**"
      ],
      "metadata": {
        "id": "7Xeuaq_NsXxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kfold_validator=KFold(10)"
      ],
      "metadata": {
        "id": "7DMPHi4bs0Fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for train_index,test_index in kfold_validator.split(x,y):\n",
        "  print('Training Index:',train_index)\n",
        "  print('Validation Index:',test_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO4MM7p2tDCE",
        "outputId": "210d66e4-0fc4-44b6-e3f3-e14a4fded044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Index: [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
            " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
            " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
            " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
            " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
            " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
            " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
            " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
            " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
            " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
            " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
            " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
            " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
            " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
            " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
            " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
            " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
            " 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611\n",
            " 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629\n",
            " 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647\n",
            " 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665\n",
            " 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683\n",
            " 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701\n",
            " 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719\n",
            " 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737\n",
            " 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755\n",
            " 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773\n",
            " 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791\n",
            " 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809\n",
            " 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827\n",
            " 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845\n",
            " 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863\n",
            " 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881\n",
            " 882 883 884 885 886 887 888 889 890]\n",
            "Validation Index: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
            " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
            " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]\n",
            "Training Index: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            " 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196\n",
            " 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214\n",
            " 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232\n",
            " 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250\n",
            " 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268\n",
            " 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286\n",
            " 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304\n",
            " 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322\n",
            " 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340\n",
            " 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358\n",
            " 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376\n",
            " 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394\n",
            " 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412\n",
            " 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430\n",
            " 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448\n",
            " 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466\n",
            " 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484\n",
            " 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502\n",
            " 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520\n",
            " 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538\n",
            " 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556\n",
            " 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574\n",
            " 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592\n",
            " 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610\n",
            " 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628\n",
            " 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646\n",
            " 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664\n",
            " 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682\n",
            " 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700\n",
            " 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718\n",
            " 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736\n",
            " 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754\n",
            " 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772\n",
            " 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790\n",
            " 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808\n",
            " 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826\n",
            " 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844\n",
            " 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862\n",
            " 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880\n",
            " 881 882 883 884 885 886 887 888 889 890]\n",
            "Validation Index: [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178]\n",
            "Training Index: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 268\n",
            " 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286\n",
            " 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304\n",
            " 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322\n",
            " 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340\n",
            " 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358\n",
            " 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376\n",
            " 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394\n",
            " 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412\n",
            " 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430\n",
            " 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448\n",
            " 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466\n",
            " 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484\n",
            " 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502\n",
            " 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520\n",
            " 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538\n",
            " 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556\n",
            " 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574\n",
            " 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592\n",
            " 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610\n",
            " 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628\n",
            " 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646\n",
            " 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664\n",
            " 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682\n",
            " 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700\n",
            " 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718\n",
            " 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736\n",
            " 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754\n",
            " 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772\n",
            " 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790\n",
            " 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808\n",
            " 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826\n",
            " 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844\n",
            " 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862\n",
            " 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880\n",
            " 881 882 883 884 885 886 887 888 889 890]\n",
            "Validation Index: [179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196\n",
            " 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214\n",
            " 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232\n",
            " 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250\n",
            " 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267]\n",
            "Training Index: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 357 358\n",
            " 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376\n",
            " 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394\n",
            " 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412\n",
            " 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430\n",
            " 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448\n",
            " 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466\n",
            " 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484\n",
            " 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502\n",
            " 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520\n",
            " 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538\n",
            " 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556\n",
            " 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574\n",
            " 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592\n",
            " 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610\n",
            " 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628\n",
            " 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646\n",
            " 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664\n",
            " 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682\n",
            " 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700\n",
            " 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718\n",
            " 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736\n",
            " 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754\n",
            " 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772\n",
            " 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790\n",
            " 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808\n",
            " 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826\n",
            " 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844\n",
            " 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862\n",
            " 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880\n",
            " 881 882 883 884 885 886 887 888 889 890]\n",
            "Validation Index: [268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285\n",
            " 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303\n",
            " 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321\n",
            " 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339\n",
            " 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356]\n",
            "Training Index: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
            " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
            " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
            " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 446 447 448\n",
            " 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466\n",
            " 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484\n",
            " 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502\n",
            " 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520\n",
            " 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538\n",
            " 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556\n",
            " 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574\n",
            " 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592\n",
            " 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610\n",
            " 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628\n",
            " 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646\n",
            " 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664\n",
            " 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682\n",
            " 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700\n",
            " 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718\n",
            " 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736\n",
            " 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754\n",
            " 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772\n",
            " 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790\n",
            " 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808\n",
            " 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826\n",
            " 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844\n",
            " 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862\n",
            " 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880\n",
            " 881 882 883 884 885 886 887 888 889 890]\n",
            "Validation Index: [357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374\n",
            " 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392\n",
            " 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410\n",
            " 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428\n",
            " 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445]\n",
            "Training Index: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
            " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
            " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
            " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
            " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
            " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
            " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
            " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
            " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 535 536 537 538\n",
            " 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556\n",
            " 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574\n",
            " 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592\n",
            " 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610\n",
            " 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628\n",
            " 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646\n",
            " 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664\n",
            " 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682\n",
            " 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700\n",
            " 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718\n",
            " 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736\n",
            " 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754\n",
            " 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772\n",
            " 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790\n",
            " 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808\n",
            " 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826\n",
            " 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844\n",
            " 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862\n",
            " 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880\n",
            " 881 882 883 884 885 886 887 888 889 890]\n",
            "Validation Index: [446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463\n",
            " 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481\n",
            " 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499\n",
            " 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517\n",
            " 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534]\n",
            "Training Index: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
            " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
            " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
            " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
            " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
            " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
            " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
            " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
            " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
            " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
            " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
            " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
            " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
            " 522 523 524 525 526 527 528 529 530 531 532 533 534 624 625 626 627 628\n",
            " 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646\n",
            " 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664\n",
            " 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682\n",
            " 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700\n",
            " 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718\n",
            " 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736\n",
            " 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754\n",
            " 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772\n",
            " 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790\n",
            " 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808\n",
            " 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826\n",
            " 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844\n",
            " 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862\n",
            " 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880\n",
            " 881 882 883 884 885 886 887 888 889 890]\n",
            "Validation Index: [535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552\n",
            " 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570\n",
            " 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588\n",
            " 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606\n",
            " 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623]\n",
            "Training Index: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
            " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
            " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
            " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
            " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
            " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
            " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
            " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
            " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
            " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
            " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
            " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
            " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
            " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
            " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
            " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
            " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
            " 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611\n",
            " 612 613 614 615 616 617 618 619 620 621 622 623 713 714 715 716 717 718\n",
            " 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736\n",
            " 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754\n",
            " 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772\n",
            " 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790\n",
            " 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808\n",
            " 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826\n",
            " 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844\n",
            " 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862\n",
            " 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880\n",
            " 881 882 883 884 885 886 887 888 889 890]\n",
            "Validation Index: [624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641\n",
            " 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659\n",
            " 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677\n",
            " 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695\n",
            " 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712]\n",
            "Training Index: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
            " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
            " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
            " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
            " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
            " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
            " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
            " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
            " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
            " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
            " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
            " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
            " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
            " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
            " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
            " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
            " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
            " 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611\n",
            " 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629\n",
            " 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647\n",
            " 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665\n",
            " 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683\n",
            " 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701\n",
            " 702 703 704 705 706 707 708 709 710 711 712 802 803 804 805 806 807 808\n",
            " 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826\n",
            " 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844\n",
            " 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862\n",
            " 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880\n",
            " 881 882 883 884 885 886 887 888 889 890]\n",
            "Validation Index: [713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730\n",
            " 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748\n",
            " 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766\n",
            " 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784\n",
            " 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801]\n",
            "Training Index: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
            " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
            " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
            " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
            " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
            " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
            " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
            " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
            " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
            " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
            " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
            " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
            " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
            " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
            " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
            " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
            " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
            " 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611\n",
            " 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629\n",
            " 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647\n",
            " 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665\n",
            " 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683\n",
            " 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701\n",
            " 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719\n",
            " 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737\n",
            " 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755\n",
            " 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773\n",
            " 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791\n",
            " 792 793 794 795 796 797 798 799 800 801]\n",
            "Validation Index: [802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819\n",
            " 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837\n",
            " 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855\n",
            " 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873\n",
            " 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "cv_result=cross_val_score(LR_model,x,y,cv=kfold_validator)"
      ],
      "metadata": {
        "id": "dhc5wfIxtkBW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b909b1ed-93b5-488b-b99b-c468b815c746"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p38LGKM-xH6G",
        "outputId": "9923e6d2-1b88-4fb6-c17e-1a09497f1ed3"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.73333333, 0.82022472, 0.76404494, 0.78651685, 0.75280899,\n",
              "       0.7752809 , 0.74157303, 0.76404494, 0.84269663, 0.78651685])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(cv_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjziiEaSxM2u",
        "outputId": "28948a49-280f-4fed-b63c-25fcf1caed06"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7767041198501873"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Stratified Cross Validation**"
      ],
      "metadata": {
        "id": "gO7APLGXzip3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "skfold_validator=StratifiedKFold(n_splits=10)"
      ],
      "metadata": {
        "id": "kg5Ps_SKxWWT"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for train_index,test_index in skfold_validator.split(x,y):\n",
        "  print('Training Index:',train_index)\n",
        "  print('Validation Index:',test_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtI4yS9Px-br",
        "outputId": "5e0b7a48-b300-4dad-de94-5fb900cee822"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Index: [ 82  84  85  88  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
            " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
            " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
            " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
            " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
            " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
            " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
            " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
            " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
            " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
            " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
            " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
            " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
            " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
            " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
            " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
            " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
            " 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611\n",
            " 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629\n",
            " 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647\n",
            " 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665\n",
            " 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683\n",
            " 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701\n",
            " 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719\n",
            " 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737\n",
            " 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755\n",
            " 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773\n",
            " 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791\n",
            " 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809\n",
            " 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827\n",
            " 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845\n",
            " 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863\n",
            " 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881\n",
            " 882 883 884 885 886 887 888 889 890]\n",
            "Validation Index: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
            " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
            " 72 73 74 75 76 77 78 79 80 81 83 86 87 89 90 91 92 93]\n",
            "Training Index: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  83  86  87  89  90  91  92  93\n",
            " 168 169 170 171 173 174 175 176 177 178 179 180 181 182 185 188 189 191\n",
            " 196 197 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214\n",
            " 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232\n",
            " 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250\n",
            " 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268\n",
            " 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286\n",
            " 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304\n",
            " 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322\n",
            " 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340\n",
            " 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358\n",
            " 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376\n",
            " 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394\n",
            " 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412\n",
            " 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430\n",
            " 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448\n",
            " 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466\n",
            " 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484\n",
            " 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502\n",
            " 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520\n",
            " 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538\n",
            " 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556\n",
            " 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574\n",
            " 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592\n",
            " 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610\n",
            " 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628\n",
            " 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646\n",
            " 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664\n",
            " 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682\n",
            " 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700\n",
            " 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718\n",
            " 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736\n",
            " 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754\n",
            " 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772\n",
            " 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790\n",
            " 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808\n",
            " 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826\n",
            " 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844\n",
            " 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862\n",
            " 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880\n",
            " 881 882 883 884 885 886 887 888 889 890]\n",
            "Validation Index: [ 82  84  85  88  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 172 183 184 186 187 190 192 193 194 195 198]\n",
            "Training Index: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 172 183 184 186 187 190 192 193 194 195 198 251\n",
            " 252 253 254 260 262 263 264 265 266 270 273 276 277 278 280 281 282 284\n",
            " 285 287 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304\n",
            " 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322\n",
            " 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340\n",
            " 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358\n",
            " 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376\n",
            " 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394\n",
            " 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412\n",
            " 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430\n",
            " 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448\n",
            " 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466\n",
            " 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484\n",
            " 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502\n",
            " 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520\n",
            " 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538\n",
            " 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556\n",
            " 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574\n",
            " 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592\n",
            " 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610\n",
            " 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628\n",
            " 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646\n",
            " 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664\n",
            " 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682\n",
            " 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700\n",
            " 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718\n",
            " 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736\n",
            " 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754\n",
            " 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772\n",
            " 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790\n",
            " 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808\n",
            " 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826\n",
            " 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844\n",
            " 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862\n",
            " 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880\n",
            " 881 882 883 884 885 886 887 888 889 890]\n",
            "Validation Index: [168 169 170 171 173 174 175 176 177 178 179 180 181 182 185 188 189 191\n",
            " 196 197 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214\n",
            " 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232\n",
            " 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250\n",
            " 255 256 257 258 259 261 267 268 269 271 272 274 275 279 283 286 288]\n",
            "Training Index: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 255\n",
            " 256 257 258 259 261 267 268 269 271 272 274 275 279 283 286 288 356 358\n",
            " 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376\n",
            " 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394\n",
            " 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412\n",
            " 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430\n",
            " 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448\n",
            " 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466\n",
            " 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484\n",
            " 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502\n",
            " 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520\n",
            " 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538\n",
            " 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556\n",
            " 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574\n",
            " 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592\n",
            " 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610\n",
            " 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628\n",
            " 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646\n",
            " 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664\n",
            " 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682\n",
            " 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700\n",
            " 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718\n",
            " 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736\n",
            " 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754\n",
            " 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772\n",
            " 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790\n",
            " 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808\n",
            " 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826\n",
            " 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844\n",
            " 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862\n",
            " 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880\n",
            " 881 882 883 884 885 886 887 888 889 890]\n",
            "Validation Index: [251 252 253 254 260 262 263 264 265 266 270 273 276 277 278 280 281 282\n",
            " 284 285 287 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303\n",
            " 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321\n",
            " 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339\n",
            " 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 357]\n",
            "Training Index: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
            " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
            " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
            " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 357 440 443 444\n",
            " 445 446 447 448 449 453 455 456 457 458 459 460 461 462 463 464 465 466\n",
            " 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484\n",
            " 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502\n",
            " 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520\n",
            " 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538\n",
            " 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556\n",
            " 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574\n",
            " 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592\n",
            " 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610\n",
            " 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628\n",
            " 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646\n",
            " 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664\n",
            " 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682\n",
            " 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700\n",
            " 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718\n",
            " 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736\n",
            " 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754\n",
            " 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772\n",
            " 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790\n",
            " 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808\n",
            " 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826\n",
            " 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844\n",
            " 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862\n",
            " 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880\n",
            " 881 882 883 884 885 886 887 888 889 890]\n",
            "Validation Index: [356 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374\n",
            " 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392\n",
            " 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410\n",
            " 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428\n",
            " 429 430 431 432 433 434 435 436 437 438 439 441 442 450 451 452 454]\n",
            "Training Index: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
            " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
            " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
            " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
            " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
            " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
            " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
            " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
            " 432 433 434 435 436 437 438 439 441 442 450 451 452 454 530 533 535 537\n",
            " 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556\n",
            " 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574\n",
            " 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592\n",
            " 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610\n",
            " 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628\n",
            " 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646\n",
            " 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664\n",
            " 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682\n",
            " 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700\n",
            " 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718\n",
            " 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736\n",
            " 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754\n",
            " 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772\n",
            " 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790\n",
            " 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808\n",
            " 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826\n",
            " 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844\n",
            " 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862\n",
            " 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880\n",
            " 881 882 883 884 885 886 887 888 889 890]\n",
            "Validation Index: [440 443 444 445 446 447 448 449 453 455 456 457 458 459 460 461 462 463\n",
            " 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481\n",
            " 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499\n",
            " 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517\n",
            " 518 519 520 521 522 523 524 525 526 527 528 529 531 532 534 536 538]\n",
            "Training Index: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
            " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
            " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
            " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
            " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
            " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
            " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
            " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
            " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
            " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
            " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
            " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
            " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
            " 522 523 524 525 526 527 528 529 531 532 534 536 538 608 609 612 615 618\n",
            " 621 622 627 630 632 634 635 636 637 638 639 640 641 642 643 644 645 646\n",
            " 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664\n",
            " 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682\n",
            " 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700\n",
            " 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718\n",
            " 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736\n",
            " 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754\n",
            " 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772\n",
            " 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790\n",
            " 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808\n",
            " 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826\n",
            " 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844\n",
            " 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862\n",
            " 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880\n",
            " 881 882 883 884 885 886 887 888 889 890]\n",
            "Validation Index: [530 533 535 537 539 540 541 542 543 544 545 546 547 548 549 550 551 552\n",
            " 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570\n",
            " 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588\n",
            " 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606\n",
            " 607 610 611 613 614 616 617 619 620 623 624 625 626 628 629 631 633]\n",
            "Training Index: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
            " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
            " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
            " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
            " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
            " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
            " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
            " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
            " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
            " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
            " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
            " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
            " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
            " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
            " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
            " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
            " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
            " 594 595 596 597 598 599 600 601 602 603 604 605 606 607 610 611 613 614\n",
            " 616 617 619 620 623 624 625 626 628 629 631 633 706 707 708 709 710 712\n",
            " 716 717 720 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736\n",
            " 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754\n",
            " 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772\n",
            " 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790\n",
            " 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808\n",
            " 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826\n",
            " 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844\n",
            " 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862\n",
            " 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880\n",
            " 881 882 883 884 885 886 887 888 889 890]\n",
            "Validation Index: [608 609 612 615 618 621 622 627 630 632 634 635 636 637 638 639 640 641\n",
            " 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659\n",
            " 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677\n",
            " 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695\n",
            " 696 697 698 699 700 701 702 703 704 705 711 713 714 715 718 719 721]\n",
            "Training Index: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
            " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
            " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
            " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
            " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
            " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
            " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
            " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
            " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
            " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
            " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
            " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
            " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
            " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
            " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
            " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
            " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
            " 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611\n",
            " 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629\n",
            " 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647\n",
            " 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665\n",
            " 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683\n",
            " 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701\n",
            " 702 703 704 705 711 713 714 715 718 719 721 797 801 802 803 804 807 808\n",
            " 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826\n",
            " 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844\n",
            " 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862\n",
            " 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880\n",
            " 881 882 883 884 885 886 887 888 889 890]\n",
            "Validation Index: [706 707 708 709 710 712 716 717 720 722 723 724 725 726 727 728 729 730\n",
            " 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748\n",
            " 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766\n",
            " 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784\n",
            " 785 786 787 788 789 790 791 792 793 794 795 796 798 799 800 805 806]\n",
            "Training Index: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
            " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
            " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
            " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
            " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
            " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
            " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
            " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
            " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
            " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
            " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
            " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
            " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
            " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
            " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
            " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
            " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
            " 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611\n",
            " 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629\n",
            " 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647\n",
            " 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665\n",
            " 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683\n",
            " 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701\n",
            " 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719\n",
            " 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737\n",
            " 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755\n",
            " 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773\n",
            " 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791\n",
            " 792 793 794 795 796 798 799 800 805 806]\n",
            "Validation Index: [797 801 802 803 804 807 808 809 810 811 812 813 814 815 816 817 818 819\n",
            " 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837\n",
            " 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855\n",
            " 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873\n",
            " 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skcv_result=cross_val_score(LR_model,x,y,cv=skfold_validator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjOlBv4kyKKI",
        "outputId": "49c025d6-9131-4e4a-9d85-310a51693dbf"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skcv_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qBkYl_9yuZr",
        "outputId": "2e16cce8-dfeb-4d25-b26e-36f3f4723db6"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.71111111, 0.76404494, 0.75280899, 0.87640449, 0.79775281,\n",
              "       0.7752809 , 0.76404494, 0.78651685, 0.79775281, 0.78651685])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(skcv_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DyvbA2PyxHy",
        "outputId": "57ada213-1228-44fa-e610-fcf9f8fade65"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7812234706616729"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F2rvvhX0y5qX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}